#!/usr/bin/env python3
"""
Benchmark for Astrological Event Analysis Agent

This benchmark evaluates the performance of an LLM-based astrological agent
in determining the favorability of specific dates and times for various events.
The evaluation uses a curated dataset with ground truth labels and measures
classification metrics including accuracy, precision, recall, and F1-score.
"""

import json
import os
from datetime import datetime
from typing import Dict, List, Tuple
from openai import OpenAI
from dotenv import load_dotenv
from pathlib import Path

# Load environment variables from project root
env_path = Path(__file__).parent.parent / '.env'
load_dotenv(env_path)


class AstroAgentBenchmark:
    """
    Benchmark suite for evaluating astrological event analysis agent.
    
    This class simulates the production environment by:
    1. Using RAG (Retrieval-Augmented Generation) to fetch astrological context
    2. Applying the same prompt template as the production agent
    3. Measuring classification performance against ground truth labels
    """
    
    def __init__(self, api_key: str, dataset: List[dict] = None):
        self.client = OpenAI(
            api_key=api_key,
            base_url="https://openrouter.ai/api/v1"
        )
        self.results = []
        # Store dataset to simulate RAG knowledge base
        self.knowledge_base = dataset if dataset else []
        
    def _simulate_rag_search(self, event_data: dict) -> str:
        """
        Simulates RAG (Retrieval-Augmented Generation) search for astrological context.
        
        In production, this would:
        1. Query FAISS vector store with event details
        2. Retrieve top-k similar document chunks
        3. Construct context from retrieved documents
        
        For benchmarking, we simulate this by retrieving the pre-defined
        astrological context from our knowledge base.
        
        Args:
            event_data: Dictionary containing event information
            
        Returns:
            Astrological context string for the event
        """
        # Simulate similarity search by finding matching event in knowledge base
        for entry in self.knowledge_base:
            if entry['id'] == event_data.get('id'):
                # Format as retrieved document chunks (similar to production)
                context = f"[Retrieved Context - Source 1]:\n{entry['astro_context']}"
                return context
        
        # Fallback if not found
        return "[Retrieved Context - Source 1]:\n–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ–π –∞—Å—Ç—Ä–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è —ç—Ç–æ–π –¥–∞—Ç—ã."
    
    def _clean_json_response(self, content: str) -> str:
        """
        Cleans LLM response from markdown formatting.
        
        Args:
            content: Raw LLM response string
            
        Returns:
            Cleaned JSON string
        """
        content = content.strip()
        
        if content.startswith("```json"):
            content = content[7:]
        elif content.startswith("```"):
            content = content[3:]
        
        if content.endswith("```"):
            content = content[:-3]
        
        return content.strip()
    
    def _create_astro_analysis_prompt(self, event_data: dict, astro_context: str) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∞—Å—Ç—Ä–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–±—ã—Ç–∏—è (–∏–∑ ai_service.py)"""
        
        event_datetime = datetime.fromisoformat(event_data['event_datetime'])
        event_name = event_data['event_name']
        event_description = event_data.get('description', '')
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞—Ç—É –∏ –≤—Ä–µ–º—è
        date_str = event_datetime.strftime('%d %B %Y')
        time_str = event_datetime.strftime('%H:%M')
        weekday_str = event_datetime.strftime('%A')
        
        prompt = f"""–¢—ã ‚Äî –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞—Å—Ç—Ä–æ–ª–æ–≥. –ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∞—Å—Ç—Ä–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–∞–π –∫—Ä–∞—Ç–∫–∏–π —Å–æ–≤–µ—Ç –æ –ø–ª–∞–Ω–∏—Ä—É–µ–º–æ–º —Å–æ–±—ã—Ç–∏–∏.

–ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –°–û–ë–´–¢–ò–ò:
–ù–∞–∑–≤–∞–Ω–∏–µ: {event_name}
–î–∞—Ç–∞: {date_str} ({weekday_str})
–í—Ä–µ–º—è: {time_str}
–û–ø–∏—Å–∞–Ω–∏–µ: {event_description if event_description else '–ù–µ —É–∫–∞–∑–∞–Ω–æ'}

–ê–°–¢–†–û–õ–û–ì–ò–ß–ï–°–ö–ò–ô –ö–û–ù–¢–ï–ö–°–¢:
{astro_context}

–ó–ê–î–ê–ß–ê:
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –±–ª–∞–≥–æ–ø—Ä–∏—è—Ç–Ω–æ—Å—Ç—å —ç—Ç–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–æ–±—ã—Ç–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞—Å—Ç—Ä–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

–¢–≤–æ–π –æ—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å:
1. –ö—Ä–∞—Ç–∫–∏–º (2-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
2. –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º (–æ—Ç–Ω–æ—Å–∏—Ç—å—Å—è –∏–º–µ–Ω–Ω–æ –∫ —ç—Ç–æ–º—É —Å–æ–±—ã—Ç–∏—é –∏ –≤—Ä–µ–º–µ–Ω–∏)
3. –ü—Ä–∞–∫—Ç–∏—á–Ω—ã–º (–¥–∞–≤–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏)
4. –û—Å–Ω–æ–≤–∞–Ω–Ω—ã–º –Ω–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–º –∞—Å—Ç—Ä–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
5. –î—Ä—É–∂–µ–ª—é–±–Ω—ã–º –∏ –ø–æ–Ω—è—Ç–Ω—ã–º (–∏–∑–±–µ–≥–∞–π —Å–ª–æ–∂–Ω—ã—Ö –∞—Å—Ç—Ä–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤, –ø–∏—à–∏ –ø—Ä–æ—Å—Ç—ã–º —è–∑—ã–∫–æ–º)
6. –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–º –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–º (–¥–∞–∂–µ –µ—Å–ª–∏ –≤—Ä–µ–º—è –Ω–µ –∏–¥–µ–∞–ª—å–Ω–æ)
7. –ï—Å–ª–∏ –≤—Ä–µ–º—è –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç, —Ç–æ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–∏ –¥—Ä—É–≥–æ–µ –≤—Ä–µ–º—è –∏–ª–∏ –¥–∞—Ç—É

–ù–µ –ø–æ–≤—Ç–æ—Ä—è–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ–±—ã—Ç–∏–∏, —Å—Ä–∞–∑—É –ø–µ—Ä–µ—Ö–æ–¥–∏ –∫ –∞—Å—Ç—Ä–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–º—É –∞–Ω–∞–ª–∏–∑—É.

–í—Å–µ–≥–¥–∞ —Å—Ç—Ä–µ–º–∏—Å—å –Ω–∞–π—Ç–∏ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã –∏ —Å—á–∏—Ç–∞—Ç—å –≤—Ä–µ–º—è —Å–∫–æ—Ä–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–º, –µ—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ —è–≤–Ω—ã–µ —Ä–∏—Å–∫–∏. 


–í–µ—Ä–Ω–∏ –æ—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON —Å–æ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π:
{{
    "result": "OK/BAD",
    "message": "–ê—Å—Ç—Ä–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"
}}
result –º–æ–∂–µ—Ç –±—ã—Ç—å —Ç–æ–ª—å–∫–æ OK –∏–ª–∏ BAD, –µ—Å–ª–∏ –≤—Ä–µ–º—è –ø–æ–¥—Ö–æ–¥–∏—Ç, —Ç–æ OK, –µ—Å–ª–∏ –Ω–µ—Ç, —Ç–æ BAD
message –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º

–ü—Ä–∏–º–µ—Ä—ã:
- {{"result": "OK", "message": "–ê—Å—Ç—Ä–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å–æ–≤–µ—Ç: —ç—Ç–æ —Ö–æ—Ä–æ—à–µ–µ –≤—Ä–µ–º—è –¥–ª—è —ç—Ç–æ–≥–æ —Å–æ–±—ã—Ç–∏—è"}}
- {{"result": "BAD", "message": "–°–æ–≥–ª–∞—Å–Ω–æ –≥–æ—Ä–æ—Å–∫–æ–ø—É, –Ω–µ–¥–µ–ª—è —Å 3 –ø–æ 9 –Ω–æ—è–±—Ä—è 2025 –≥–æ–¥–∞ –¥–ª—è –∑–Ω–∞–∫–∞ –í–æ–¥–æ–ª–µ–π –Ω–µ –æ–ø–∏—Å–∞–Ω–∞,
    –Ω–æ –¥–ª—è –∑–Ω–∞–∫–∞ –°–∫–æ—Ä–ø–∏–æ–Ω —ç—Ç–∞ –Ω–µ–¥–µ–ª—è ‚Äî –≤—Ä–µ–º—è –º—É–¥—Ä–æ—Å—Ç–∏ –∏ –∑–∞–±–æ—Ç—ã –æ —Å–µ–±–µ, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Å–ª—É—à–∞—Ç—å —Å–≤–æ—ë —Å–µ—Ä–¥—Ü–µ –∏ –Ω–µ —É—Å–ª–æ–∂–Ω—è—Ç—å –∑–∞–¥–∞—á–∏.
    –≠—Ç–æ –º–æ–∂–µ—Ç –≥–æ–≤–æ—Ä–∏—Ç—å –æ —Ç–æ–º, —á—Ç–æ —Å–µ–π—á–∞—Å –Ω–µ —Å–∞–º–æ–µ –±–ª–∞–≥–æ–ø—Ä–∏—è—Ç–Ω–æ–µ –≤—Ä–µ–º—è –¥–ª—è –≤–∞–∂–Ω—ã—Ö –≤—Å—Ç—Ä–µ—á, —Ç—Ä–µ–±—É—é—â–∏—Ö –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏–∏ –∏ –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π.
    –ù–∞–ø—É—Ç—Å—Ç–≤–∏–µ: –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ–Ω–µ—Å—Ç–∏ –≤—Å—Ç—Ä–µ—á—É –Ω–∞ –±–æ–ª–µ–µ –±–ª–∞–≥–æ–ø—Ä–∏—è—Ç–Ω–æ–µ –≤—Ä–µ–º—è, –Ω–∞–ø—Ä–∏–º–µ—Ä, –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é –Ω–µ–¥–µ–ª—é."}}
- {{"result": "OK", "message": "–ê—Å—Ç—Ä–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å–æ–≤–µ—Ç: –ó–∞–≤—Ç—Ä–∞—à–Ω–∏–µ —Ç—Ä–∞–Ω–∑–∏—Ç—ã –≤—ã–≥–ª—è–¥—è—Ç —Å–ø–æ–∫–æ–π–Ω—ã–º–∏ ‚Äî –¥–∞–∂–µ –µ—Å–ª–∏ –¥–µ–Ω—å –≤ —Ü–µ–ª–æ–º –∫–∞–∂–µ—Ç—Å—è —ç–Ω–µ—Ä–≥–∏—á–µ—Å–∫–∏ –Ω–µ—Ä–æ–≤–Ω—ã–º, –≤ –≤–∞—à–µ–π –ª–∏—á–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –Ω–µ—Ç –Ω–∞–ø—Ä—è–∂—ë–Ω–Ω—ã—Ö –∞—Å–ø–µ–∫—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥–ª–∏ –±—ã –ø–æ–º–µ—à–∞—Ç—å –≤—Å—Ç—Ä–µ—á–µ. –í–ª–∏—è–Ω–∏–µ –ø–ª–∞–Ω–µ—Ç —Å–∫–æ—Ä–µ–µ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–µ, —Ç–∞–∫ —á—Ç–æ —Å–º–µ–ª–æ –Ω–∞–∑–Ω–∞—á–∞–π—Ç–µ —Å–æ–±—ã—Ç–∏–µ: –≤—Ä–µ–º—è –æ–±–µ—â–∞–µ—Ç –ø—Ä–æ–π—Ç–∏ —É—Å—Ç–æ–π—á–∏–≤–æ –∏ –±–µ–∑ –Ω–µ–ø—Ä–∏—è—Ç–Ω—ã—Ö —Å—é—Ä–ø—Ä–∏–∑–æ–≤."}}

"""
        
        return prompt
    
    def evaluate_sample(self, sample: dict) -> dict:
        """
        Evaluates a single sample from the dataset.
        
        Simulates the production pipeline:
        1. RAG retrieval of astrological context
        2. Prompt construction with retrieved context
        3. LLM inference
        4. Response parsing and validation
        
        Args:
            sample: Test sample containing event data and ground truth label
            
        Returns:
            Evaluation result dictionary with predictions and metadata
        """
        print(f"üîÆ Evaluating event #{sample['id']}: {sample['event_name']}...")
        
        try:
            # Step 1: Simulate RAG retrieval (as in production ai_service.py)
            astro_context = self._simulate_rag_search(sample)
            
            # Step 2: Construct prompt with retrieved context
            prompt = self._create_astro_analysis_prompt(sample, astro_context)
            
            # Step 3: LLM inference with production model and parameters
            response = self.client.chat.completions.create(
                model="openai/gpt-4o-mini",
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,  # Low temperature for consistent predictions
                max_tokens=10000
            )
            
            content = response.choices[0].message.content
            
            # Step 4: Parse and validate response
            cleaned_content = self._clean_json_response(content)
            prediction = json.loads(cleaned_content)
            
            predicted_result = prediction.get('result', 'UNKNOWN')
            expected_result = sample['expected_result']
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å
            is_correct = predicted_result == expected_result
            
            result = {
                'id': sample['id'],
                'event_name': sample['event_name'],
                'expected': expected_result,
                'predicted': predicted_result,
                'correct': is_correct,
                'message': prediction.get('message', ''),
                'raw_response': content[:200]  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            }
            
            status = "‚úÖ" if is_correct else "‚ùå"
            print(f"  {status} –û–∂–∏–¥–∞–ª–∏: {expected_result}, –ü–æ–ª—É—á–∏–ª–∏: {predicted_result}")
            
            return result
            
        except Exception as e:
            print(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}")
            return {
                'id': sample['id'],
                'event_name': sample['event_name'],
                'expected': sample['expected_result'],
                'predicted': 'ERROR',
                'correct': False,
                'message': str(e),
                'raw_response': ''
            }
    
    def calculate_metrics(self, results: List[dict]) -> Dict[str, float]:
        """–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        
        # –ü–æ–¥—Å—á–µ—Ç True Positive, True Negative, False Positive, False Negative
        tp = sum(1 for r in results if r['expected'] == 'OK' and r['predicted'] == 'OK')
        tn = sum(1 for r in results if r['expected'] == 'BAD' and r['predicted'] == 'BAD')
        fp = sum(1 for r in results if r['expected'] == 'BAD' and r['predicted'] == 'OK')
        fn = sum(1 for r in results if r['expected'] == 'OK' and r['predicted'] == 'BAD')
        
        total = len(results)
        errors = sum(1 for r in results if r['predicted'] == 'ERROR')
        
        # Accuracy
        accuracy = (tp + tn) / total if total > 0 else 0
        
        # Precision (–∏–∑ —Ç–µ—Ö, —á—Ç–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∏ OK, —Å–∫–æ–ª—å–∫–æ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö)
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        
        # Recall (–∏–∑ –≤—Å–µ—Ö OK, —Å–∫–æ–ª—å–∫–æ –Ω–∞—à–ª–∏)
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        
        # F1-Score
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        
        return {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'total_samples': total,
            'correct_predictions': tp + tn,
            'errors': errors,
            'true_positive': tp,
            'true_negative': tn,
            'false_positive': fp,
            'false_negative': fn
        }
    
    def run_benchmark(self, dataset_path: str) -> Tuple[List[dict], Dict[str, float]]:
        """–ó–∞–ø—É—Å–∫ –±–µ–Ω—á–º–∞—Ä–∫–∞ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ"""
        print(f"üìä –ù–∞—á–∏–Ω–∞–µ–º –±–µ–Ω—á–º–∞—Ä–∫ –∞—Å—Ç—Ä–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–≥–µ–Ω—Ç–∞")
        print(f"üìÅ –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç –∏–∑: {dataset_path}\n")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
        with open(dataset_path, 'r', encoding='utf-8') as f:
            dataset = json.load(f)
        
        print(f"‚ú® –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(dataset)} –ø—Ä–∏–º–µ—Ä–æ–≤\n")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –ø—Ä–∏–º–µ—Ä
        results = []
        for i, sample in enumerate(dataset, 1):
            print(f"[{i}/{len(dataset)}]", end=" ")
            result = self.evaluate_sample(sample)
            results.append(result)
            print()
        
        # –°—á–∏—Ç–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
        print("\n" + "="*80)
        print("üìà –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫...")
        metrics = self.calculate_metrics(results)
        
        return results, metrics
    
    def save_metrics_report(self, metrics: Dict[str, float], results: List[dict], output_path: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –≤ Markdown"""
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("# üîÆ –û—Ç—á–µ—Ç –ø–æ –±–µ–Ω—á–º–∞—Ä–∫—É –∞—Å—Ç—Ä–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–≥–µ–Ω—Ç–∞\n\n")
            
            # –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            f.write(f"**–î–∞—Ç–∞ –∑–∞–ø—É—Å–∫–∞:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"**–ú–æ–¥–µ–ª—å:** OpenAI GPT-4o-mini (—á–µ—Ä–µ–∑ OpenRouter)\n")
            f.write(f"**–í—Å–µ–≥–æ –ø—Ä–∏–º–µ—Ä–æ–≤:** {metrics['total_samples']}\n\n")
            
            # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            f.write("## üìä –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n\n")
            f.write("| –ú–µ—Ç—Ä–∏–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ | –û–ø–∏—Å–∞–Ω–∏–µ |\n")
            f.write("|---------|----------|----------|\n")
            f.write(f"| **Accuracy** | {metrics['accuracy']:.2%} | –î–æ–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π |\n")
            f.write(f"| **Precision** | {metrics['precision']:.2%} | –¢–æ—á–Ω–æ—Å—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π (OK) |\n")
            f.write(f"| **Recall** | {metrics['recall']:.2%} | –ü–æ–ª–Ω–æ—Ç–∞ (–∫–∞–∫—É—é –¥–æ–ª—é OK —Å–æ–±—ã—Ç–∏–π –Ω–∞—à–ª–∏) |\n")
            f.write(f"| **F1-Score** | {metrics['f1']:.2%} | –ì–∞—Ä–º–æ–Ω–∏—á–µ—Å–∫–æ–µ —Å—Ä–µ–¥–Ω–µ–µ Precision –∏ Recall |\n\n")
            
            # –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            f.write("## üìà –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n\n")
            f.write("| –ü–æ–∫–∞–∑–∞—Ç–µ–ª—å | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ |\n")
            f.write("|------------|------------|\n")
            f.write(f"| –í—Å–µ–≥–æ –ø—Ä–∏–º–µ—Ä–æ–≤ | {metrics['total_samples']} |\n")
            f.write(f"| –ü—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π | {metrics['correct_predictions']} |\n")
            f.write(f"| –û—à–∏–±–æ—á–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π | {metrics['total_samples'] - metrics['correct_predictions'] - metrics['errors']} |\n")
            f.write(f"| –û—à–∏–±–æ–∫ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ | {metrics['errors']} |\n\n")
            
            # Confusion Matrix
            f.write("## üéØ –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ (Confusion Matrix)\n\n")
            f.write("|  | Predicted OK | Predicted BAD |\n")
            f.write("|---|---|---|\n")
            f.write(f"| **Actual OK** | {metrics['true_positive']} (TP) | {metrics['false_negative']} (FN) |\n")
            f.write(f"| **Actual BAD** | {metrics['false_positive']} (FP) | {metrics['true_negative']} (TN) |\n\n")
            
            # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫
            f.write("## üí° –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n\n")
            
            if metrics['accuracy'] >= 0.8:
                f.write("‚ú® **–û—Ç–ª–∏—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç!** –ú–æ–¥–µ–ª—å —Ö–æ—Ä–æ—à–æ —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –±–ª–∞–≥–æ–ø—Ä–∏—è—Ç–Ω–æ—Å—Ç–∏ –≤—Ä–µ–º–µ–Ω–∏.\n\n")
            elif metrics['accuracy'] >= 0.6:
                f.write("üëç **–•–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç.** –ú–æ–¥–µ–ª—å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø—Ä–∏–µ–º–ª–µ–º—É—é —Ç–æ—á–Ω–æ—Å—Ç—å, –Ω–æ –µ—Å—Ç—å –∫—É–¥–∞ —Ä–∞—Å—Ç–∏.\n\n")
            else:
                f.write("‚ö†Ô∏è **–¢—Ä–µ–±—É–µ—Ç—Å—è —É–ª—É—á—à–µ–Ω–∏–µ.** –ú–æ–¥–µ–ª—å —á–∞—Å—Ç–æ –æ—à–∏–±–∞–µ—Ç—Å—è –≤ –æ—Ü–µ–Ω–∫–µ –±–ª–∞–≥–æ–ø—Ä–∏—è—Ç–Ω–æ—Å—Ç–∏.\n\n")
            
            # –ê–Ω–∞–ª–∏–∑ —Ç–∏–ø–æ–≤ –æ—à–∏–±–æ–∫
            if metrics['false_positive'] > metrics['false_negative']:
                f.write("- **–°–∫–ª–æ–Ω–Ω–æ—Å—Ç—å –∫ –æ–ø—Ç–∏–º–∏–∑–º—É:** –ú–æ–¥–µ–ª—å —á–∞—â–µ –≥–æ–≤–æ—Ä–∏—Ç OK, –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ —Å–∫–∞–∑–∞—Ç—å BAD (False Positives).\n")
                f.write("- –≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –∞–≥–µ–Ω—Ç –º–æ–∂–µ—Ç –æ–¥–æ–±—Ä—è—Ç—å –Ω–µ–±–ª–∞–≥–æ–ø—Ä–∏—è—Ç–Ω–æ–µ –≤—Ä–µ–º—è.\n\n")
            elif metrics['false_negative'] > metrics['false_positive']:
                f.write("- **–°–∫–ª–æ–Ω–Ω–æ—Å—Ç—å –∫ –ø–µ—Å—Å–∏–º–∏–∑–º—É:** –ú–æ–¥–µ–ª—å —á–∞—â–µ –≥–æ–≤–æ—Ä–∏—Ç BAD, –∫–æ–≥–¥–∞ –≤—Ä–µ–º—è –±–ª–∞–≥–æ–ø—Ä–∏—è—Ç–Ω–æ (False Negatives).\n")
                f.write("- –≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –∞–≥–µ–Ω—Ç –º–æ–∂–µ—Ç –æ—Ç–≥–æ–≤–∞—Ä–∏–≤–∞—Ç—å –æ—Ç —Ö–æ—Ä–æ—à–∏—Ö –º–æ–º–µ–Ω—Ç–æ–≤.\n\n")
            else:
                f.write("- **–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å:** –û—à–∏–±–∫–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω—ã —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ.\n\n")
            
            # –ü—Ä–∏–º–µ—Ä—ã –æ—à–∏–±–æ–∫
            f.write("## ‚ùå –ü—Ä–∏–º–µ—Ä—ã –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\n\n")
            
            errors = [r for r in results if not r['correct'] and r['predicted'] != 'ERROR']
            
            if errors:
                f.write("### False Positives (—Å–∫–∞–∑–∞–ª–∏ OK, –∞ –Ω–∞–¥–æ –±—ã–ª–æ BAD)\n\n")
                fp_errors = [e for e in errors if e['expected'] == 'BAD' and e['predicted'] == 'OK']
                if fp_errors:
                    for err in fp_errors[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
                        f.write(f"- **{err['event_name']}** (ID: {err['id']})\n")
                        f.write(f"  - –û–∂–∏–¥–∞–ª–∏: {err['expected']}, –ü–æ–ª—É—á–∏–ª–∏: {err['predicted']}\n\n")
                else:
                    f.write("_–¢–∞–∫–∏—Ö –æ—à–∏–±–æ–∫ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ_\n\n")
                
                f.write("### False Negatives (—Å–∫–∞–∑–∞–ª–∏ BAD, –∞ –Ω–∞–¥–æ –±—ã–ª–æ OK)\n\n")
                fn_errors = [e for e in errors if e['expected'] == 'OK' and e['predicted'] == 'BAD']
                if fn_errors:
                    for err in fn_errors[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
                        f.write(f"- **{err['event_name']}** (ID: {err['id']})\n")
                        f.write(f"  - –û–∂–∏–¥–∞–ª–∏: {err['expected']}, –ü–æ–ª—É—á–∏–ª–∏: {err['predicted']}\n\n")
                else:
                    f.write("_–¢–∞–∫–∏—Ö –æ—à–∏–±–æ–∫ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ_\n\n")
            else:
                f.write("üéâ **–û—à–∏–±–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!** –ú–æ–¥–µ–ª—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∞ –≤—Å–µ –ø—Ä–∏–º–µ—Ä—ã.\n\n")
            
            # –ó–∞–∫–ª—é—á–µ–Ω–∏–µ
            f.write("## üé≠ –ó–∞–∫–ª—é—á–µ–Ω–∏–µ\n\n")
            f.write("–≠—Ç–æ—Ç –±–µ–Ω—á–º–∞—Ä–∫ - —à—É—Ç–æ—á–Ω—ã–π, –Ω–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–µ–∞–ª—å–Ω—É—é —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å ")
            f.write("–∞—Å—Ç—Ä–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –¥–∞–≤–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏. –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã ")
            f.write("–º–æ–≥—É—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –ø–æ–ª–Ω–æ—Ç—ã –∞—Å—Ç—Ä–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö.\n\n")
            
            f.write("_–°–æ–∑–≤–∞–Ω–æ –∑–≤–µ–∑–¥–∞–º–∏, –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ –∫–æ–¥–æ–º_ ‚ú®üîÆ\n")
        
        print(f"\nüíæ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {output_path}")


def main():
    """
    Main entry point for the benchmark execution.
    
    Loads configuration, initializes the benchmark suite, runs evaluation,
    and generates a comprehensive metrics report.
    """
    # Load API key from environment
    api_key = os.getenv('OPENAI_API_KEY')
    
    if not api_key:
        print("‚ùå Error: OPENAI_API_KEY not found in .env file")
        print("   Please create .env file in project root with OPENAI_API_KEY=your_key")
        return
    
    # Define file paths
    script_dir = Path(__file__).parent
    dataset_path = script_dir / 'dataset.json'
    output_path = script_dir / 'metrics.md'
    
    # Validate dataset exists
    if not dataset_path.exists():
        print(f"‚ùå Error: Dataset not found at {dataset_path}")
        return
    
    # Load dataset for RAG knowledge base simulation
    print(f"üìÅ Loading dataset from: {dataset_path}")
    with open(dataset_path, 'r', encoding='utf-8') as f:
        dataset = json.load(f)
    
    # Initialize benchmark with dataset (for RAG simulation)
    benchmark = AstroAgentBenchmark(api_key, dataset=dataset)
    results, metrics = benchmark.run_benchmark(str(dataset_path))
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
    benchmark.save_metrics_report(metrics, results, str(output_path))
    
    # –í—ã–≤–æ–¥–∏–º –∏—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ –∫–æ–Ω—Å–æ–ª—å
    print("\n" + "="*80)
    print("üéØ –ò–¢–û–ì–û–í–´–ï –ú–ï–¢–†–ò–ö–ò:")
    print("="*80)
    print(f"Accuracy:  {metrics['accuracy']:.2%}")
    print(f"Precision: {metrics['precision']:.2%}")
    print(f"Recall:    {metrics['recall']:.2%}")
    print(f"F1-Score:  {metrics['f1']:.2%}")
    print("="*80)
    print(f"\n‚úÖ –ë–µ–Ω—á–º–∞—Ä–∫ –∑–∞–≤–µ—Ä—à–µ–Ω! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ {output_path} –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞.")


if __name__ == "__main__":
    main()

